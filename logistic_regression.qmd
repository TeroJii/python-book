---
jupyter: python3
---

# Logistic regression

In the previous chapter we learned about linear regression. The word regression is used in the context of statistical modelling to refer to the act of estimating the relationship between a dependent variable and one or more independent variables. However, sometimes what we are trying to predict might not be a continuous numerical variable, but categorical. In such cases, instead of a regression problem, we are dealing with classification. In the simplest case, there are only two distinct classes. This is called binary classification. One of the simplests algorithms for solving these types of problems is called logistic regression, which despite its name, is used for classification.

## Univariate logistic regression

In univariate logistic regression, we have a single independent variable and a binary dependent variable. The goal is to estimate the probability that the dependent variable is 1, based on the value of the independent variable. This implies that the values of the categorical dependent variable are assigned so-called dummy values, and are therefore coded as 0 and 1. For example, if we are trying to predict whether a student will pass or fail an exam based on the number of hours they studied, we can code the dependent variable as 1 if the student passed and 0 if they failed.

The logistic function is used to model the relationship between the inpedendent and dependent variables. The logistic function is defined as:

$$
y = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x)}},
$$ {#eq-logistic}

where $y$ is again the dependent variable, and $x$ is the independent variable, and $\beta_0$ and $\beta_1$ are the parameters of the model. As you might have noticed, the exponential term contains the linear regression equation. This is not a coincidence. The logistic regression uses something called the sigmoid function, which basically transforms the output of the linear regression into a probability. The sigmoid function is defined as:

$$
\sigma(z) = \frac{1}{1 + e^{-z}}.
$$ {#eq-sigmoid}

If we plot out the sigmoid function, we can see that it has a distinct shape, which somewhat resembles the letter S. @fig-sigmoid shows the sigmoid function with $z$ on the x-axis and $\sigma(z)$ on the y-axis.

```{python}
#| label: fig-sigmoid
#| fig-cap: The shape of the sigmoid function has a distinct S-like shape.

import numpy as np
import matplotlib.pyplot as plt

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

z = np.linspace(-10, 10, 100)

plt.plot(z, sigmoid(z))
plt.xlabel('z')
plt.ylabel('Ïƒ(z)')
plt.title('Sigmoid function')

plt.show()
```

### Evaluating the model

Something about the confusion matrix.