[
  {
    "objectID": "control_flow.html",
    "href": "control_flow.html",
    "title": "2  Control Flow Statements",
    "section": "",
    "text": "2.1 The if statement\nThe if statement evaluates a condition and based on it’s value (True or False) it will execute or skip a block of code.\nif True:\n    print('This will be printed')\n\nif False:\n    print('This will not be printed')\n\nThis will be printed\nWe are not limited to using boolean values in the condition. We can use any expression that evaluates to a boolean value.\nname = 'Tero'\n\nif name == 'Tero':\n    # code block to be executed if the condition is True\n    print('Hello Tero!')\n\nHello Tero!\nYou should note that unlike some other programming languages, Python does not use curly braces to define code blocks. Instead, Python uses indentation. The code block should be indented with 4 spaces. Most (all?) modern code editors should handle this automatically, so you needn’t worry about it too much.",
    "crumbs": [
      "The Very Basics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Control Flow Statements</span>"
    ]
  },
  {
    "objectID": "control_flow.html#the-if-statement",
    "href": "control_flow.html#the-if-statement",
    "title": "2  Control Flow Statements",
    "section": "",
    "text": "2.1.1 Extending the if statement with elif and else\nWhat if we want to execute some code also if the condition is False? We can use the else statement for that.\n\nname = 'Antero'\n\nif name == 'Tero':\n    print('Hello Tero!')\nelse:\n    print('Hello stranger!')\n\nHello stranger!\n\n\nAnd in the case of multiple conditions, we can use the elif statement to check for additional conditions if the previous conditions were False.\n\nname = 'Antero'\n\nif name == 'Tero':\n    print('Hello Tero!')\nelif name == 'Antero':\n    print(\"Oh, it's you again!\")\nelse:\n    print('Hello stranger!')\n\nOh, it's you again!\n\n\nThat is the basic idea behind the if-else statement. You can have as many elif statements as you want, but only one (or none) else statement which is located at the end. Conditions can also be nested.\n\nname = 'Tero'\nage = 30\n\nif name == 'Tero':\n    if age &lt; 18:\n        print('Hello young Tero!')\n    else:\n        print('Hello adult Tero!')\nelse:\n    print('Hello stranger!')\n\nHello adult Tero!",
    "crumbs": [
      "The Very Basics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Control Flow Statements</span>"
    ]
  },
  {
    "objectID": "control_flow.html#the-for-loop",
    "href": "control_flow.html#the-for-loop",
    "title": "2  Control Flow Statements",
    "section": "2.2 The for loop",
    "text": "2.2 The for loop\nThe idea behind a loop structure is to repeat a block of code multiple times. The for loop is used when we know how many times we want to repeat the code block.\n\nseasons = ['Spring', 'Summer', 'Autumn', 'Winter']\n\nfor season in seasons:\n    print('It is now {}'.format(season))\n\nIt is now Spring\nIt is now Summer\nIt is now Autumn\nIt is now Winter\n\n\nThe for loop iterates over the elements of the seasons list. In each iteration, the variable season is assigned the value of the current element. The loop continues until all elements have been iterated over. This is useful for example when we need to repeat a calculation several times.\n\nsquared_numbers = []\n\nfor i in range(1, 6):\n    squared_numbers.append(i**2)\n\nprint(squared_numbers)\n\n[1, 4, 9, 16, 25]",
    "crumbs": [
      "The Very Basics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Control Flow Statements</span>"
    ]
  },
  {
    "objectID": "control_flow.html#the-while-loop",
    "href": "control_flow.html#the-while-loop",
    "title": "2  Control Flow Statements",
    "section": "2.3 The while loop",
    "text": "2.3 The while loop\nThe while loop is the for loop’s liberal cousin. It is less restrictive and repeats a block of code as long as a condition is True. Depending on the condition we might not know how many times the loop will be executed beforehand. The price for this freedom is that we might accidentally create an infinite loop if we’re not careful. Let’s look at a simple example.\n\ncount = 0\n\nwhile count &lt; 5:\n    print('Count is {}'.format(count))\n    count += 1\n\nCount is 0\nCount is 1\nCount is 2\nCount is 3\nCount is 4\n\n\nThe example above could have been implemented with a for loop as well. As a rule of thumb a forloop can always be written as a while loop, but not the other way around. We’ll come back to more complicated while loops later, when we learn about random number generation and the break and continue statements.",
    "crumbs": [
      "The Very Basics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Control Flow Statements</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Basic Data Types\nNumbers, strings and booleans are some of the most basic data types found in Python. Let’s quickly go through some basic operations that can be performed on these data types.",
    "crumbs": [
      "The Very Basics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#basic-data-types",
    "href": "intro.html#basic-data-types",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1.1 Working with numbers\nNumbers can be categorized into integers and floats, depending on the use of a decimal point. Both can be used for performing basic arithmetics as shown below:\n\n1 + 1\n\n2\n\n\n\n1.0 + 2.5\n\n3.5\n\n\nThis as such is not super useful. However, we can assign numbers (as well as other data types) into variables, which will help us store and manipulate data:\n\nmy_iq = 259\n\nprint(my_iq)\n\n259\n\n\nWhen we input large numbers, we can use underscores to make them more readable:\n\nnumber_of_people_reading_this_book = 1_000_000\n\nnumber_of_people_reading_this_book\n\n1000000\n\n\nBasic arithmetic operations can be performed on numbers using the following syntax:\n\na = 10\nb = 3\n\n# addition\na + b\n\n13\n\n\n\n# subtraction\na - b\n\n7\n\n\n\n# multiplication\na * b\n\n30\n\n\n\n# division\na / b\n\n3.3333333333333335\n\n\n\n# floor division\na // b\n\n3\n\n\n\n# modulo\na % b\n\n1\n\n\n\n# exponentiation\na ** b\n\n1000\n\n\n\n\n\n\n\n\nCaution\n\n\n\nWhen working with floating point numbers, we might encounter some precision issues stemming from the way computers store numbers. For example, you would expect the following code to return 0.0, but it doesn’t due to the aforementioned limitations:\n\n1 - 0.7 - 0.3\n\n5.551115123125783e-17\n\n\nThis is usually not a problem, but it’s good to keep in mind nevertheless.\n\n\n\n\n1.1.2 Strings\nStrings are used to represent text data. They can be enclosed in either single ' or double \" quotes. Some basic operations on strings include concatenation and repetition:\n\n\"Hello\" + \" \" + \"World\"\n\n'Hello World'\n\n\n\n\"Hello\" * 3\n\n'HelloHelloHello'\n\n\nStrings can also be indexed and sliced:\n\nmy_string = \"Hello World\"\n\n# indexing\nprint(my_string[0])\n\nH\n\n\n\n# slicing\nprint(my_string[0:5])\n\nHello\n\n\nSometimes we might have to convert numbers to strings and vice versa. This can be done using the str() and int() functions:\n\n# converting a number to a string\nstr(123)\n\n'123'\n\n\n\nstring_disguised_as_number = '123'\n\n# converting a string to a number\nint(string_disguised_as_number)\n\n123\n\n\nIn case of floats, we can use the float() function:\n\n# converting a string to a float\nfloat('3.14')\n\n3.14\n\n\nIf you need to create a string which spans multiple lines, you can use triple quotes to do so:\n\nmultiline_string =\"\"\"\nThis is a string\nthat spans multiple\nlines\n\"\"\"\nprint(multiline_string)\n\n\nThis is a string\nthat spans multiple\nlines\n\n\n\nThe three quotation marks are basically just a shorthand for creating a string with newline characters in it, as we can see if we print out the string variable:\n\nmultiline_string\n\n'\\nThis is a string\\nthat spans multiple\\nlines\\n'\n\n\nSometimes it is useful to format strings in a certain way. This can be done using the format() method:\n\nname = \"John\"\nage = 25\nformatted_string = \"My name is {} and I am {} years old\".format(name, age)\n\nprint(formatted_string)\n\nMy name is John and I am 25 years old\n\n\nThere are other intricacies related to working with strings, such as the split() and join() methods, which we will cover in a later section… maybe.\n\n\n1.1.3 Booleans\nBooleans are used to represent truth values, namely True and False. They can be used in conjunction with logical operators such as and, or and not:\n\nTrue and False\n\nFalse\n\n\nBooleans are most commonly used in conditional statements, which we will cover in a later section.",
    "crumbs": [
      "The Very Basics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#other-data-types",
    "href": "intro.html#other-data-types",
    "title": "1  Introduction",
    "section": "1.2 Other data types",
    "text": "1.2 Other data types\nPython has a number of built-in data structures that can be used to store collections of data. Some of the most commonly used ones are lists, tuples, sets and dictionaries.\n\n1.2.1 Lists\nLists are used to store collections of items. They are ordered, mutable and can contain items of different types. Lists are defined using square brackets []:\n\nmy_list = [1, 'two', True, False, 5]\n\nprint(my_list)\n\n[1, 'two', True, False, 5]\n\n\nYou can access elements in a list using their index. Just remember that Python uses zero-based indexing:\n\n# get second element\nmy_list[1]\n\n'two'\n\n\nYou can also slice lists, i.e. get a subset of the list using the following syntax:\n\n# get first three elements\nmy_list[:3]\n\n[1, 'two', True]\n\n\nNegative indices can be used to access elements from the end of the list:\n\n# get the last element\nmy_list[-1]\n\n5\n\n\nA list can also contain nested lists:\n\nnested_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\nprint(nested_list)\n\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\n\nAccessing the elements of a nested list is done by chaining the index operators:\n\nnested_list[1][2]\n\n6\n\n\nThis can be tricky at times. Consider yourself warned.\nAdding new elements to a list can be done using the append() method:\n\nmy_list.append('New element')\n\nprint(my_list)\n\n[1, 'two', True, False, 5, 'New element']\n\n\nWe can return the last element from a list using the pop() method:\n\nmy_list.pop()\n\n'New element'\n\n\nThis will also remove it from the list as we can see by inspecting the list again:\n\nprint(my_list)\n\n[1, 'two', True, False, 5]\n\n\nIf we want to remove a specific element from our list, we can do so by using the remove() method:\n\nmy_list.remove('two')\n\nprint(my_list)\n\n[1, True, False, 5]\n\n\n\n\n1.2.2 Tuples\nTuples are kind of like lists, but they are immutable, which is a fancy way of saying that once they are created, their size and contents cannot be changed. Tuples are defined using parentheses ():\n\n# creating a tuple\nmy_tuple = (1, 'two', True, False, 5)\n\nmy_tuple\n\n(1, 'two', True, False, 5)\n\n\nYou can access elements in a tuple using their index, just like with lists:\n\n# get second element\nmy_tuple[1]\n\n'two'\n\n\nWhy would you then create a tuple instead of a list? Well, tuples are faster than lists, and I guess sometimes you want to make sure that the data you are working with doesn’t change to name a few reasons.\n\n\n1.2.3 Sets\nSets are kind of like lists or tuples, but they are unordered and do not allow duplicate elements. Sets are defined using curly braces {}:\n\nmy_set = {1, 2, 3}\n\nmy_set\n\n{1, 2, 3}\n\n\nThere is also a set() function can be used to create a set, but we won’t go into that here. Sets are mutable, so you can add and remove elements from them. They are also useful for performing set operations such as union, intersection, difference and symmetric difference:\n\nset1 = {1, 2, 3}\nset2 = {3, 4, 5}\n\n# union\nset1 | set2\n\n{1, 2, 3, 4, 5}\n\n\n\n# intersection\nset1 & set2\n\n{3}\n\n\n\n# difference\n\nset1 - set2\n\n{1, 2}\n\n\n\n# symmetric difference\nset1 ^ set2\n\n{1, 2, 4, 5}\n\n\n\n\n1.2.4 Dictionaries\nLast but not least we have dictionaries, which are used to store key-value pairs. Dictionaries are unordered, mutable and can contain items of different types. Dictionaries are defined using curly braces {}:\n\nmy_dict = {'name': 'Tero', 'likes': 'Pizza', 'is_student': False, 'age': 25}\n\nYou can access the value of a key in a dictionary using the key itself:\n\nmy_dict['name']\n\n'Tero'\n\n\nThat’s it. We have covered the basics of Python data types. Phew! Pat yourself on the back for making it this far, and treat yourself to a cup of coffee or a slice of pizza. You deserve it! Next up, we will cover control flow statements in Python. Exciting… I know!",
    "crumbs": [
      "The Very Basics",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "3  Functions",
    "section": "",
    "text": "3.1 Built-in functions\nLet’s take a look at a few built-in functions and how they can be used. Here are a few examples (some of which we’ve already encountered):\nUsing basic functions is dead simple. Usually the function has some arguments which the user passes on to the function as input. Let’s try the functions above to get a feel for how they work:\nmy_list = [\"Hello\", \"I'm\", 1, \"list\", True]\n\nprint(my_list)\n\n['Hello', \"I'm\", 1, 'list', True]\nSo, we see that the print() function can be used to print out the contents of the input parameter into the console. Makes sense, right?\nIf we inspect the type of the my_list variable, we can (rather unsurprisingly) see that it is a list:\ntype(my_list)\n\nlist\nWe can also confirm that the third element of the list is an integer:\ntype(my_list[2])\n\nint\nAnd finally, our list contains 5 elements in total, as we can see when we pass my_list to the len() function:\nlen(my_list)\n\n5\nThat’s the basics of using built-in functions. There are loads of other functions, but we won’t cover them here. They are best learned when needed. Next we’ll see how to build our own functions.",
    "crumbs": [
      "The Very Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "functions.html#built-in-functions",
    "href": "functions.html#built-in-functions",
    "title": "3  Functions",
    "section": "",
    "text": "print(): prints the given argument(s) to the console\ntype(): returns the type of the given argument\nlen(): returns the length of the given argument",
    "crumbs": [
      "The Very Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "functions.html#user-defined-functions",
    "href": "functions.html#user-defined-functions",
    "title": "3  Functions",
    "section": "3.2 User-defined functions",
    "text": "3.2 User-defined functions\nCustom-made functions are a way to encapsulate code that you want to reuse. They are defined using the def keyword, followed by the function name, and a colon.\n\n# creating a custom function\ndef my_function():\n    # enter the code you wish to run below\n    # note that the indentation is important here as well\n    print(\"Hello I'm a custom-made function!\")\n\n# calling the function\nmy_function()\n\nHello I'm a custom-made function!\n\n\nAlthough the function above isn’t particulrly useful, it is still a valid function. We can make our functions more useful by adding some parameters when defining them.\n\n# creating a custom function with parameters\ndef my_function_with_args(name):\n    print(f\"Hello {name}, I'm a custom-made function with arguments!\")\n\n# we can now pass an argument to the function when calling it\nmy_function_with_args(\"John\")\n\nHello John, I'm a custom-made function with arguments!\n\n\nWe can also return values from functions. This is done using the return keyword.\n\ndef num_squared(num = 2):\n    returned_value = num ** 2\n    return returned_value\n\nnum_squared()\n\n4\n\n\nAs we saw above, we can also set default values for the parameters of the function. The default value will be used if the user doesn’t pass any arguments to the function.\n\n\n\n\n\n\nNote\n\n\n\nVariables defined inside a function are not accessible outside of it. For example, we can’t directly call the returned_value variable outside of the num_squared function. This is called the scope of the variable.\n\n\n\n3.2.1 Documenting your function\nIt is a good practice to document your functions. This is done by adding something called a docstring to the function. A docstring is a string that is placed at the beginning of the function and is enclosed in triple quotes. You can include text that describes what the function does and how it is used, i.e., what arguments it takes, and what it returns. This is especially useful with more complex functions.\n\ndef my_function_with_args(name):\n    \"\"\"\n    This function takes a name as an argument and prints a greeting.\n    \"\"\"\n    print(f\"Hello {name}, I'm a custom-made function with arguments!\")\n\nThe docstring can be accessed by using the __doc__ attribute of the function.\n\nprint(my_function_with_args.__doc__)\n\n\n    This function takes a name as an argument and prints a greeting.",
    "crumbs": [
      "The Very Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "functions.html#lambda-expressions",
    "href": "functions.html#lambda-expressions",
    "title": "3  Functions",
    "section": "3.3 Lambda expressions",
    "text": "3.3 Lambda expressions\nLamdas are a way to create small, anonymous functions. They are defined using the lambda keyword, followed by the arguments, a colon, and the expression to evaluate.\nLet’s say we have a simple function, which can be described in one line of code. We can naturally define a proper function like this:\n\ndef add(a, b):\n    return a + b\n\nHowever, we can also accomplish the same by using a lambda expression:\n\nlambda a, b: a + b\n\n&lt;function __main__.&lt;lambda&gt;(a, b)&gt;\n\n\nWe can use the following syntax to pass arguments to the lambda expression for evaluation:\n\n(lambda a, b: a + b)(2, 3)\n\n5\n\n\nNow, why would we want to do this you might ask?\nLet’s say we want to raise a bunch of numbers to the second power. We could do this by first defining a function and the passing it on to the map() function, which applies the function to each element of a list.\n\ndef squared(x):\n    return x ** 2\n\nlist(map(squared, [1, 2, 3, 4, 5]))\n\n[1, 4, 9, 16, 25]\n\n\nThis works, and is perfectly fine. However, the squared() function is quite simple, so it seems a bit silly to write a separate function for this. Here is where the lambda expression comes in handy. It allows us to accomplish the same thing in a more concise way:\n\n# same with a lambda expression\nlist(map(lambda x: x ** 2, [1, 2, 3, 4, 5]))\n\n[1, 4, 9, 16, 25]\n\n\nWe get the same result, but with less code. Lambda expressions are especially useful when you need to pass a simple function as an argument to another function. We will work more with them once we familiarize ourselves with Pandas DataFrames.",
    "crumbs": [
      "The Very Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "functions.html#methods",
    "href": "functions.html#methods",
    "title": "3  Functions",
    "section": "3.4 Methods",
    "text": "3.4 Methods\nWhat are methods and how do they differ from functions? In Python, methods are functions that are associated with an object. They are called using the dot notation, i.e., object.method(). A common methods associated with strings is the upper() method, which converts all characters in a string to uppercase. Let’s take a look shall we?\n\nmy_string = \"hello, I'm a string\"\n\nmy_string.upper()\n\n\"HELLO, I'M A STRING\"\n\n\nYou can browse methods associated with an object by using the dir() function. This will return a list of all the methods associated with the object.\n\n# storing the methods associated with the my_string object in a variable\nmethods_for_my_string = dir(my_string)\n\n# printing the last 5 methods\nmethods_for_my_string[-5:]\n\n['swapcase', 'title', 'translate', 'upper', 'zfill']\n\n\nYou can also use the help() function to get more information about a method. This will return a description of the method, as well as the arguments it takes.\n\nhelp(my_string.upper)\n\nHelp on built-in function upper:\n\nupper() method of builtins.str instance\n    Return a copy of the string converted to uppercase.\n\n\n\nWhat makes methods so powerful is that they can be chained together. This means that you can call multiple methods on the same object in a single line of code. Let’s see an example of this:\n\nmy_string.upper().split()\n\n['HELLO,', \"I'M\", 'A', 'STRING']",
    "crumbs": [
      "The Very Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "pandas.html",
    "href": "pandas.html",
    "title": "5  Pandas Basics",
    "section": "",
    "text": "5.1 Series\nSeries is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the index. The basic method to create a Series is to call the series constructor:\n# import numpy and pandas libraries\nimport numpy as np\nimport pandas as pd\n\n# create a series from a list\npd.Series(data = [1, 2, 3, 4])\n\n0    1\n1    2\n2    3\n3    4\ndtype: int64\nWe can see that the series look very much like the list or a NumPy array. The series also has an index that can be used to access the elements of the series, but the difference is that we can specify the index values for our series:\n# create a series with custom index\nmy_series = pd.Series(data = [1, 2, 3, 4], index = ['a', 'b', 'c', 'd'])\nmy_series\n\na    1\nb    2\nc    3\nd    4\ndtype: int64\nWe can access the elements of the series using the index values:\n# access the elements of the series\nmy_series['a']\n\n1\nYou can also use the dot notation:\n# access the elements of the series using the dot notation\nmy_series.b\n\n2",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas Basics</span>"
    ]
  },
  {
    "objectID": "linear_regression.html",
    "href": "linear_regression.html",
    "title": "7  Linear regression",
    "section": "",
    "text": "Code\nimport seaborn as sns\n\niris = sns.load_dataset('iris')\niris.head()\n\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa",
    "crumbs": [
      "Modelling",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Linear regression</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "8  Summary",
    "section": "",
    "text": "In summary, this book is a work in progress.\n\n\nCode\nprint(\"Thanks for reading!\")\n\n\nThanks for reading!",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Python Bytes: A Poor Man’s Guide to Wrestling with Data",
    "section": "",
    "text": "Preface\n\n\nCode\nprint('Hello World!')\n\n\nHello World!\n\n\nHi, I’m Tero and I work as a data scientist. I’ve been mainly programming with R for the past 7 years or so. However, I’ve started recently to use Python more as well. This book is meant as a reference for myself as I’m learning to use Python more efficiently. Hence, it will be a living document for the time being. The focus will be on using Python for analysing data. Let’s find out where this journey leads.\n\n\n\n\n\n\nNote\n\n\n\nNote if you are looking to really learn Python. Then I recommend reading a book like Wes McKinney’s Python for data analysis McKinney (2022). That being said, I do hope that this book will become a useful reference to some core concepts in Python.\n\n\n\n\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. O’Reilly Media. https://wesmckinney.com/book/.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "functions.html#using-help-for-functions-and-classes",
    "href": "functions.html#using-help-for-functions-and-classes",
    "title": "3  Functions",
    "section": "3.5 Using help() for functions and classes",
    "text": "3.5 Using help() for functions and classes\nHelp is a great way to get more information about a method, especially when you are not sure how to use it. It also works for functions and classes.\n\nhelp(help)\n\nHelp on _Helper in module _sitebuiltins object:\n\nclass _Helper(builtins.object)\n |  Define the builtin 'help'.\n |  \n |  This is a wrapper around pydoc.help that provides a helpful message\n |  when 'help' is typed at the Python interactive prompt.\n |  \n |  Calling help() at the Python prompt starts an interactive help session.\n |  Calling help(thing) prints help for the python object 'thing'.\n |  \n |  Methods defined here:\n |  \n |  __call__(self, *args, **kwds)\n |      Call self as a function.\n |  \n |  __repr__(self)\n |      Return repr(self).\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables\n |  \n |  __weakref__\n |      list of weak references to the object\n\n\n\n\nhelp(list)\n\nHelp on class list in module builtins:\n\nclass list(object)\n |  list(iterable=(), /)\n |  \n |  Built-in mutable sequence.\n |  \n |  If no argument is given, the constructor creates a new empty list.\n |  The argument must be an iterable if specified.\n |  \n |  Methods defined here:\n |  \n |  __add__(self, value, /)\n |      Return self+value.\n |  \n |  __contains__(self, key, /)\n |      Return key in self.\n |  \n |  __delitem__(self, key, /)\n |      Delete self[key].\n |  \n |  __eq__(self, value, /)\n |      Return self==value.\n |  \n |  __ge__(self, value, /)\n |      Return self&gt;=value.\n |  \n |  __getattribute__(self, name, /)\n |      Return getattr(self, name).\n |  \n |  __getitem__(...)\n |      x.__getitem__(y) &lt;==&gt; x[y]\n |  \n |  __gt__(self, value, /)\n |      Return self&gt;value.\n |  \n |  __iadd__(self, value, /)\n |      Implement self+=value.\n |  \n |  __imul__(self, value, /)\n |      Implement self*=value.\n |  \n |  __init__(self, /, *args, **kwargs)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  __iter__(self, /)\n |      Implement iter(self).\n |  \n |  __le__(self, value, /)\n |      Return self&lt;=value.\n |  \n |  __len__(self, /)\n |      Return len(self).\n |  \n |  __lt__(self, value, /)\n |      Return self&lt;value.\n |  \n |  __mul__(self, value, /)\n |      Return self*value.\n |  \n |  __ne__(self, value, /)\n |      Return self!=value.\n |  \n |  __repr__(self, /)\n |      Return repr(self).\n |  \n |  __reversed__(self, /)\n |      Return a reverse iterator over the list.\n |  \n |  __rmul__(self, value, /)\n |      Return value*self.\n |  \n |  __setitem__(self, key, value, /)\n |      Set self[key] to value.\n |  \n |  __sizeof__(self, /)\n |      Return the size of the list in memory, in bytes.\n |  \n |  append(self, object, /)\n |      Append object to the end of the list.\n |  \n |  clear(self, /)\n |      Remove all items from list.\n |  \n |  copy(self, /)\n |      Return a shallow copy of the list.\n |  \n |  count(self, value, /)\n |      Return number of occurrences of value.\n |  \n |  extend(self, iterable, /)\n |      Extend list by appending elements from the iterable.\n |  \n |  index(self, value, start=0, stop=9223372036854775807, /)\n |      Return first index of value.\n |      \n |      Raises ValueError if the value is not present.\n |  \n |  insert(self, index, object, /)\n |      Insert object before index.\n |  \n |  pop(self, index=-1, /)\n |      Remove and return item at index (default last).\n |      \n |      Raises IndexError if list is empty or index is out of range.\n |  \n |  remove(self, value, /)\n |      Remove first occurrence of value.\n |      \n |      Raises ValueError if the value is not present.\n |  \n |  reverse(self, /)\n |      Reverse *IN PLACE*.\n |  \n |  sort(self, /, *, key=None, reverse=False)\n |      Sort the list in ascending order and return None.\n |      \n |      The sort is in-place (i.e. the list itself is modified) and stable (i.e. the\n |      order of two equal elements is maintained).\n |      \n |      If a key function is given, apply it once to each list item and sort them,\n |      ascending or descending, according to their function values.\n |      \n |      The reverse flag can be set to sort in descending order.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods defined here:\n |  \n |  __class_getitem__(...) from builtins.type\n |      See PEP 585\n |  \n |  ----------------------------------------------------------------------\n |  Static methods defined here:\n |  \n |  __new__(*args, **kwargs) from builtins.type\n |      Create and return a new object.  See help(type) for accurate signature.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __hash__ = None\n\n\n\nThat’s it for functions and methods. We will use them extensively in the upcoming chapters, so make sure you understand how they work.",
    "crumbs": [
      "The Very Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Functions</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Here you can find a list of useful references that were used in the creation of this book.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. O’Reilly Media.\nhttps://wesmckinney.com/book/.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "numpy.html",
    "href": "numpy.html",
    "title": "4  NumPy",
    "section": "",
    "text": "4.1 Installation and Loading\nYou can install Python packages using the pip command. Another popular package manager is conda. Either of these package managers will do the trick.\nOnce you have installed the NumPy package, you can load it using the following command.\nimport numpy as np\nWe have imported the NumPy package and aliased it as np. This is a common convention when working with NumPy. We can now use the functions and classes provided by NumPy by prefixing them with np.. For example, generating a random number using NumPy would look like this:\nnp.random.rand(5)\n\narray([0.97880901, 0.04743252, 0.94166398, 0.76965014, 0.43116348])",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#intallation-and-loading",
    "href": "numpy.html#intallation-and-loading",
    "title": "4  NumPy",
    "section": "",
    "text": "Tip\n\n\n\nYou can install NumPy using the following command:\npip install numpy",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#installation-and-loading",
    "href": "numpy.html#installation-and-loading",
    "title": "4  NumPy",
    "section": "",
    "text": "Tip\n\n\n\nInstalling NumPy using pip in rather simple. Just run the following command in your terminal or command prompt:\npip install numpy",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#what-can-numpy-do",
    "href": "numpy.html#what-can-numpy-do",
    "title": "4  NumPy",
    "section": "4.2 What can NumPy do?",
    "text": "4.2 What can NumPy do?\nOne of the key concepts in NumPy are array and matrix data structures. Moreover, Numpy provides tools for working with these structures. The array is in principle quite similar to a list in Python, with a few key differences:\n\nArrays can be multidimensional\nArrays can only contain elements of the same type, whereas lists can contain elements of different types\nArrays are optimized for numerical operations, whereas lists are not. This makes arrays much faster for numerical operations than lists, and also more memory efficient.",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#creating-numpy-arrays",
    "href": "numpy.html#creating-numpy-arrays",
    "title": "4  NumPy",
    "section": "4.3 Creating NumPy Arrays",
    "text": "4.3 Creating NumPy Arrays\n\n4.3.1 Creating 1-D NumPy Arrays\nYou can create a 1-D NumPy array from a list using the np.array() function. For example:\n\na = np.array([1, 2, 3, 4, 5])\nprint(a)\n\n[1 2 3 4 5]",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#numpy-arrays",
    "href": "numpy.html#numpy-arrays",
    "title": "4  NumPy",
    "section": "4.3 NumPy Arrays",
    "text": "4.3 NumPy Arrays\nYou can create a 1-D NumPy array from a list using the np.array() function. For example:\n\na = np.array([1, 2, 3, 4, 5])\na\n\narray([1, 2, 3, 4, 5])\n\n\nYou might have noticed that we actually used a list to create the NumPy array. We can naturally create a NumPy array from a list which has been assigned to a variable. For example, below we will cast a list to an array using the variable my_list:\n\nmy_list = [0, 1, 2, 3, 4, 5]\na = np.array(my_list)\nprint(a)\n\n[0 1 2 3 4 5]\n\n\nNow accessing the elements of the array is similar to accessing the elements of a list. For example, to access the first element of the array, you can use the following code:\n\na[0]\n\n0\n\n\nThis works just like it would for a list:\n\nmy_list[0]\n\n0\n\n\nYou can also use the slice notation to access a range of elements in the array. For example, the following code will access the elements from the second to the fourth element of the array. So in other words from index one to index three (it can be confusing I know).\n\na[1:4]\n\narray([1, 2, 3])\n\n\nWith arrays you can also do something called broadcasting. This means that you can apply an operation to every element in the array. For example, the following code will multiply every element in the array by 2.\n\na * 2\n\narray([ 0,  2,  4,  6,  8, 10])\n\n\nThis is not possible with lists as you will see by looking at the example below.\n\nmy_list * 2\n\n[0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]\n\n\nYou can also apply mathematical functions to the array. For example, the following code will calculate the square of first three elements in the array.\n\nsquare_first_three = np.square(a[:3])\nprint(square_first_three)\n\n[0 1 4]\n\n\nYou should be aware that the array is not changed by these operations, as we can see by printing the array.\n\na\n\narray([0, 1, 2, 3, 4, 5])\n\n\n\n\n\n\n\n\nWarning\n\n\n\nHowever, when you broadcast on a slice of an array, the original array is changed. For example, the following code will change the first three elements of the array to their squares.\n\nsquared_slice = a[:3]\nsquared_slice **= 2\n\nprint(squared_slice)\nprint(a)\n\n[0 1 4]\n[0 1 4 3 4 5]\n\n\n\n\nYou can use the copy() method to create a copy of the array. This way you can change the copy without changing the original array. For example, the following code will create a copy of the array and change the copy without changing the original array.\n\na_copy = a.copy()\na_copy[0] = 100\nprint(a_copy)\nprint(a)\n\n[100   1   4   3   4   5]\n[0 1 4 3 4 5]\n\n\n\n4.3.1 Other Ways to Create 1-D Arrays\nnp.array() is not the only way to create a NumPy array. We can also create a one dimensional NumPy array for a range of numbers conveniently using the np.arange() function.\n\na = np.arange(1, 6)\nprint(a)\n\n[1 2 3 4 5]\n\n\nYou can also determine a step size for the range of numbers. For example, the following code will create an array with numbers from 0 to 10 with a step size of 2.\n\na_steps = np.arange(0, 11, 2)\nprint(a_steps)\n\n[ 0  2  4  6  8 10]\n\n\n\n\n4.3.2 2-D Matrices\nYou can create a 2-D NumPy array from a list of lists by using the np.array() function.\n\nb = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nb\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n\n\nYou can access elements of a 2-D array using two indices. For example, the following code will access the element in the second row and third column of the array.\n\n# index for the second row and third column\nb[1, 2]\n\n6\n\n\nThere is also a double bracket notation for accessing elements in a 2-D array. For example, the following code will access the element in the second row and third column of the array.\n\nb[1][2]\n\n6\n\n\nEither of the two methods will work, but the first method should be more efficient.",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#some-convenient-functions",
    "href": "numpy.html#some-convenient-functions",
    "title": "4  NumPy",
    "section": "4.4 Some convenient functions",
    "text": "4.4 Some convenient functions\nHere are some convenient functions that you can use to create NumPy arrays:\n\nnp.zeros(): Creates an array of zeros\nnp.ones(): Creates an array of ones\nnp.linspace(): Creates an array of evenly spaced numbers over a specified range\nnp.eye(): Creates an identity matrix\n\nLet’s see some examples.\n\n4.4.1 Zeros and Ones\nYou can create an array of zeros using the np.zeros() function. For example, the following code will create an array of zeros with 5 elements.\n\nnp.zeros(5)\n\narray([0., 0., 0., 0., 0.])\n\n\nFor a 2-D array, you can specify the shape of the array as a tuple. For example, the following code will create a 2-D array of zeros with 3 rows and 4 columns.\n\nnp.zeros((3, 4))\n\narray([[0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.]])\n\n\nUsing ones is similar to using zeros. Let’s create a 5 by 6 matrix of ones.\n\nnp.ones((5, 6))\n\narray([[1., 1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1., 1.],\n       [1., 1., 1., 1., 1., 1.]])\n\n\n\n\n4.4.2 Linspace\nThe np.linspace() function is used to create an array of evenly spaced numbers over a specified range. For example, the following code will create an array of 10 numbers between 0 and 5.\n\nnp.linspace(0, 5, 10)\n\narray([0.        , 0.55555556, 1.11111111, 1.66666667, 2.22222222,\n       2.77777778, 3.33333333, 3.88888889, 4.44444444, 5.        ])\n\n\nHow does it differ from np.arange() you might ask? The np.linspace() function will always include the start and end values, whereas the np.arange() function will not include the end value.\n\n\n4.4.3 Eye\nThis function is used for creating an identity matrix. An identity matrix is a square matrix with ones on the diagonal and zeros elsewhere. We can create a 4 by 4 identity matrix with the following code.\n\nnp.eye(4)\n\narray([[1., 0., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.]])\n\n\nThe identity matrix has many important uses in linear algebra and other areas of mathematics.",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#array-operations",
    "href": "numpy.html#array-operations",
    "title": "4  NumPy",
    "section": "4.6 Array Operations",
    "text": "4.6 Array Operations\nYou can perform element-wise operations on NumPy arrays. For example, you can add two arrays together, subtract one array from another, multiply two arrays, and divide one array by another. Let’s see some examples.\n\n4.6.1 Basic Operations\nYou can perform basic arithmetic operations on NumPy arrays. For example, the following code will add two arrays together.\n\na = np.array([1, 2, 3, 4, 5])\n\na + a\n\narray([ 2,  4,  6,  8, 10])\n\n\nThe same goes for subtraction and multiplication.\n\n# subtraction\na - a\n\narray([0, 0, 0, 0, 0])\n\n\n\n# multiplication\na * a\n\narray([ 1,  4,  9, 16, 25])\n\n\nYou can also divide two arrays:\n\na / a\n\narray([1., 1., 1., 1., 1.])\n\n\nScalar operations are also possible. For example, the following code will multiply every element in the array by 2.\n\na * 2\n\narray([ 2,  4,  6,  8, 10])\n\n\nYou can also add or subtract a scalar from an array.\n\n# addition\na + 2\n\narray([3, 4, 5, 6, 7])\n\n\n\n\n4.6.2 Universal Functions\nNumPy provides a number of universal functions that can be applied to arrays. For example, the np.sqrt() function calculates the square root of every element in the array.\n\nnp.sqrt(a)\n\narray([1.        , 1.41421356, 1.73205081, 2.        , 2.23606798])\n\n\nYou can do things like finding the maximum or minimum value in an array.\n\n# maximum value\nnp.max(a)\n\n5\n\n\nThis is equivalent to using the max() method.\n\na.max()\n\n5\n\n\nYou can also find the index of the maximum value in the array.\n\nnp.argmax(a)\n\n4\n\n\nTrigonometric functions are also available, such as np.sin(), np.cos(), and np.tan().\n\nnp.cos(a)\n\narray([ 0.54030231, -0.41614684, -0.9899925 , -0.65364362,  0.28366219])\n\n\nThere are many more universal functions available in NumPy. You can find a list of them in the NumPy documentation. That’s it for NumPy. In the next section, we will look at Pandas, which will introduce us to DataFrames, a powerful data structure for data analysis in Python.",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "numpy.html#numpy-for-random-number-generation",
    "href": "numpy.html#numpy-for-random-number-generation",
    "title": "4  NumPy",
    "section": "4.5 NumPy for Random Number Generation",
    "text": "4.5 NumPy for Random Number Generation\nRandom numbers are needed for a variety of purposes in data analysis and machine learning. NumPy provides a number of functions for generating random numbers. Here are some of the most commonly used functions:\n\nnp.random.rand(): Generates random numbers from a uniform distribution\nnp.random.randn(): Generates random numbers from a standard normal distribution\nnp.random.randint(): Generates random integers\n\nThese functions allow us to create NumPy arrays with random numbers taken from different distributions.\n\n4.5.1 Uniform Distribution\nThe uniform distribution refers generally to random numbers between 0 and 1. The np.random.rand() function generates random numbers from a uniform distribution. For example, the following code will generate an array of 5 random numbers between 0 and 1.\n\nnp.random.rand(5)\n\narray([0.92448441, 0.90400502, 0.92213011, 0.92029374, 0.74739645])\n\n\nYou can also generate a 2-D array of random numbers. For example, the following code will generate a 3 by 4 array of random numbers.\n\narr = np.random.rand(3, 4)\narr\n\narray([[0.53633468, 0.80503591, 0.48212329, 0.49865715],\n       [0.4211912 , 0.69433433, 0.87418408, 0.23662667],\n       [0.14847428, 0.61232323, 0.6030776 , 0.458986  ]])\n\n\nWe can always check the shape of the array using the shape attribute.\n\narr.shape\n\n(3, 4)\n\n\nThe shape attribute returns a tuple with the dimensions of the array. In this case, the array has 3 rows and 4 columns. The function reshape() allows us to change the shape of the array. For example, we can reshape the array to have 4 rows and 3 columns, or to be one dimensional.\n\narr.reshape(4, 3)\n\narray([[0.53633468, 0.80503591, 0.48212329],\n       [0.49865715, 0.4211912 , 0.69433433],\n       [0.87418408, 0.23662667, 0.14847428],\n       [0.61232323, 0.6030776 , 0.458986  ]])\n\n\n\narr.reshape(12)\n\narray([0.53633468, 0.80503591, 0.48212329, 0.49865715, 0.4211912 ,\n       0.69433433, 0.87418408, 0.23662667, 0.14847428, 0.61232323,\n       0.6030776 , 0.458986  ])\n\n\nYou might have noticed, but the two dimensional array has two square brackets on the outer edges, whereas the one dimensional array has only one square bracket per side.\nFinally, we can also check the data type of the array using the dtype attribute. In case we want to change the data type of the array, we can use the astype() method.\n\narr.dtype\n\ndtype('float64')\n\n\n\narr.astype(int)\n\narray([[0, 0, 0, 0],\n       [0, 0, 0, 0],\n       [0, 0, 0, 0]])\n\n\n\n\n4.5.2 Normal Distribution\nThe normal distribution is quite possibly the most important distribution in statistics. The np.random.randn() function generates random numbers from a standard normal distribution. If we want to save ourselves some typing we can import the function directly.\n\nfrom numpy.random import randn\n\nThis allows us to use the function without the np. prefix. Like this:\n\n# create 5 random numbers from a standard normal distribution\nrandn(5)\n\narray([ 1.16773318, -1.03230255,  1.18685319,  0.27572565, -1.89376463])\n\n\nThe standard normal distribution is centered around zero and has a standard deviation of one. So, if we want to change the mean and standard deviation of our normal distribution, we can multiply the random numbers by the standard deviation and shift the mean by addition. For example, the following code will generate 5 random numbers from a normal distribution with a mean of 10 and a standard deviation of 2.\n\n# multiply by sd and add mean\nrandn(5) * 2 + 10\n\narray([10.73838116,  8.23491577,  9.79708733, 10.38771634,  9.32476956])\n\n\n\n\n4.5.3 Random Integers\nThe np.random.randint() function generates random integers. For example, the following code will generate eight random integers between 0 and 10.\n\nfrom numpy.random import randint\n\nrandint(0, 10, 8)\n\narray([7, 7, 9, 4, 0, 3, 3, 0])\n\n\nIf you want the results to be reproducible, you can set the seed using the np.random.seed() function. For example, the following code will generate the same random numbers every time you run it.\n\nnp.random.seed(42)\nrandint(0, 10, 8)\n\narray([6, 3, 7, 4, 6, 9, 2, 6])\n\n\nThe this code draws numbers with replacement from the integers between 0 and 10. If you want to draw numbers without replacement, you can use the choice() function. For example, the following code will draw 5 random numbers without replacement from the integers between 0 and 10.\n\nnp.random.choice(10, 5, replace=False)\n\narray([0, 6, 9, 1, 8])",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "pandas.html#series",
    "href": "pandas.html#series",
    "title": "5  Pandas Basics",
    "section": "",
    "text": "5.1.1 Creating a Series from other data types\nA List is not the only data type that can be used to create a series. You can also use a dictionary:\n\n# creating a series from a dictionary\nmy_dict = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\npd.Series(my_dict)\n\na    1\nb    2\nc    3\nd    4\ndtype: int64\n\n\nYou can also create a series from a NumPy array etc.\n\n# creating a series from a NumPy array\nmy_array = np.array([1, 2, 3, 4])\npd.Series(my_array)\n\n0    1\n1    2\n2    3\n3    4\ndtype: int32\n\n\n\n\n5.1.2 Accessing elements of a Series\nWe already saw the bracket + index and the dot + index notation in action. In addition to using the index, we can use the iloc attribute to access the elements of the series by using numerical indexing:\n\n# access the first element of the series by using the positional index\nmy_series.iloc[0]\n\n1\n\n\nYou can also use the loc attribute to access the elements of the series by their index. You can add multiple index values to access multiple elements:\n\n# access the elements of the series by their index\nmy_series.loc[['a', 'c']]\n\na    1\nc    3\ndtype: int64\n\n\nWe can also use the : operator to access a range of elements:\n\n# access a range of elements\nmy_series.loc['a':'c']\n\na    1\nb    2\nc    3\ndtype: int64\n\n\nAssigning values to the elements of the series is also possible and works in the same way as with NumPy arrays:\n\n# assign a value to an element of the series\nmy_series['a'] = 100\nmy_series\n\na    100\nb      2\nc      3\nd      4\ndtype: int64",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas Basics</span>"
    ]
  },
  {
    "objectID": "pandas.html#dataframe",
    "href": "pandas.html#dataframe",
    "title": "5  Pandas Basics",
    "section": "5.2 DataFrame",
    "text": "5.2 DataFrame\nA DataFrame is a two-dimensional, size-mutable, and heterogeneous tabular data structure with labeled axes (rows and columns). You can think of being similar to a spreadsheet. It is generally the most commonly used pandas object. Like the Series object we learned earlier, the DataFrame also accepts many different kinds of input. Let’s see what a DataFrame looks like:\n\n# create a DataFrame from a dictionary\ndata = {'name': ['John', 'Anna', 'Peter', 'Linda'],\n        'age': [23, 36, 32, 45],\n        'city': ['New York', 'Paris', 'Berlin', 'London']}\n\ndf = pd.DataFrame(data)\ndf\n\n\n\n\n\n\n\n\n\nname\nage\ncity\n\n\n\n\n0\nJohn\n23\nNew York\n\n\n1\nAnna\n36\nParis\n\n\n2\nPeter\n32\nBerlin\n\n\n3\nLinda\n45\nLondon\n\n\n\n\n\n\n\n\nWe can see that the DataFrame has a default index that starts from 0, and that the data is displayed in a tabular format which makes it easy to read. We can also specify the index values:\n\n# create a DataFrame with custom index\ndf = pd.DataFrame(data, index = ['a', 'b', 'c', 'd'])\ndf\n\n\n\n\n\n\n\n\n\nname\nage\ncity\n\n\n\n\na\nJohn\n23\nNew York\n\n\nb\nAnna\n36\nParis\n\n\nc\nPeter\n32\nBerlin\n\n\nd\nLinda\n45\nLondon\n\n\n\n\n\n\n\n\n\n5.2.1 Accessing Columns of a DataFrame\nThe columns are actually Pandas Series objects. We can access the columns of the DataFrame using the column name and the bracket notation. Let’s access the ‘name’ column of the DataFrame:\n\n# access the first column of the DataFrame\ndf['name']\n\na     John\nb     Anna\nc    Peter\nd    Linda\nName: name, dtype: object\n\n\nLet’s inspect the type of the column:\n\ntype(df['name'])\n\npandas.core.series.Series\n\n\nWe can see that the column is a Pandas Series object. We can also access the columns using the dot notation:\n\ndf.name\n\na     John\nb     Anna\nc    Peter\nd    Linda\nName: name, dtype: object\n\n\nThe issue that we may run into using the dot notation is that it may not work if the column we are trying to access has the same name as a DataFrame method. For example, if we have a column named ‘count’, we cannot access it using the dot notation because ‘count’ is a DataFrame method. We can access the columns using the loc attribute:\n\n# add count column to the DataFrame\ndf['count'] = [1, 2, 3, 4]\ndf\n\n\n\n\n\n\n\n\n\nname\nage\ncity\ncount\n\n\n\n\na\nJohn\n23\nNew York\n1\n\n\nb\nAnna\n36\nParis\n2\n\n\nc\nPeter\n32\nBerlin\n3\n\n\nd\nLinda\n45\nLondon\n4\n\n\n\n\n\n\n\n\nWe can access the columns using the loc attribute:\n\n# access the columns of the DataFrame using the loc attribute\ndf.loc[:, 'count']\n\na    1\nb    2\nc    3\nd    4\nName: count, dtype: int64\n\n\nAs we saw above, we can create a new column by assigning a list to a new column name. We can also create a new column by using the existing columns:\n\n# create a new column by using the existing columns\ndf['age_plus_count'] = df['age'] + df['count']\ndf\n\n\n\n\n\n\n\n\n\nname\nage\ncity\ncount\nage_plus_count\n\n\n\n\na\nJohn\n23\nNew York\n1\n24\n\n\nb\nAnna\n36\nParis\n2\n38\n\n\nc\nPeter\n32\nBerlin\n3\n35\n\n\nd\nLinda\n45\nLondon\n4\n49\n\n\n\n\n\n\n\n\nIf we now want to access all the new columns we created, we can use the bracket notation:\n\n# access the new columns\ndf[['count', 'age_plus_count']]\n\n\n\n\n\n\n\n\n\ncount\nage_plus_count\n\n\n\n\na\n1\n24\n\n\nb\n2\n38\n\n\nc\n3\n35\n\n\nd\n4\n49\n\n\n\n\n\n\n\n\nNow you might be wondering how to delete a column. We can use the drop method to delete a column:\n\n# deleting the new columns\ndf.drop(['count', 'age_plus_count'], axis=1)\n\n\n\n\n\n\n\n\n\nname\nage\ncity\n\n\n\n\na\nJohn\n23\nNew York\n\n\nb\nAnna\n36\nParis\n\n\nc\nPeter\n32\nBerlin\n\n\nd\nLinda\n45\nLondon\n\n\n\n\n\n\n\n\nThis prints out the DataFrame without the columns. However, you should note that the drop method does not modify the original DataFrame by default. We can confirm this by printing the original DataFrame:\n\ndf\n\n\n\n\n\n\n\n\n\nname\nage\ncity\ncount\nage_plus_count\n\n\n\n\na\nJohn\n23\nNew York\n1\n24\n\n\nb\nAnna\n36\nParis\n2\n38\n\n\nc\nPeter\n32\nBerlin\n3\n35\n\n\nd\nLinda\n45\nLondon\n4\n49\n\n\n\n\n\n\n\n\nIf you want to remove the columns permanently, you need to use the inplace parameter:\n\n# deleting the new columns permanently\ndf.drop(['count', 'age_plus_count'], axis=1, inplace=True)\ndf\n\n\n\n\n\n\n\n\n\nname\nage\ncity\n\n\n\n\na\nJohn\n23\nNew York\n\n\nb\nAnna\n36\nParis\n\n\nc\nPeter\n32\nBerlin\n\n\nd\nLinda\n45\nLondon\n\n\n\n\n\n\n\n\nThis gives us the original DataFrame without the columns we deleted. You might have noticed how we specified axis = 1 in the drop method. This is used to refer to dropping columns. Rows are dropped by specifying axis = 0. The terminology comes from NumPy, where the first axis is the rows and the second axis is the columns.\n\n\n5.2.2 Accessing Rows of a DataFrame\nOk, so we know how to access the columns of a DataFrame. How do we access the rows? There are a number of ways to do this. For example, we can use the loc attribute to access the rows of a DataFrame by their index:\n\n# access the rows of the DataFrame by their index\nrow_a = df.loc['a']\n\nrow_a\n\nname        John\nage           23\ncity    New York\nName: a, dtype: object\n\n\nIf we inspect the type of row_a, we can see that it is also a Pandas Series object, just like the individual columns were Series objects as well:\n\ntype(row_a)\n\npandas.core.series.Series\n\n\nHow do we access multiple rows? We can use the loc attribute and pass a list of index values:\n\n# access multiple rows\ndf.loc[['a', 'c']]\n\n\n\n\n\n\n\n\n\nname\nage\ncity\n\n\n\n\na\nJohn\n23\nNew York\n\n\nc\nPeter\n32\nBerlin\n\n\n\n\n\n\n\n\nThis, in turn, returns back a DataFrame. We can also use the iloc attribute to access the rows by their numerical index:\n\n# get the last two rows of the DataFrame\ndf.iloc[2:]\n\n\n\n\n\n\n\n\n\nname\nage\ncity\n\n\n\n\nc\nPeter\n32\nBerlin\n\n\nd\nLinda\n45\nLondon\n\n\n\n\n\n\n\n\nWe can also use the slicing notation for DataFrames. For example, to get the first two rows of the DataFrame:\n\ndf[:2]\n\n\n\n\n\n\n\n\n\nname\nage\ncity\n\n\n\n\na\nJohn\n23\nNew York\n\n\nb\nAnna\n36\nParis\n\n\n\n\n\n\n\n\nDo you still remember the drop method we used to delete columns? As we already discussed, we can also use it to delete rows. Let’s delete the first row:\n\n# delete the first row\ndf.drop('a', axis=0)\n\n\n\n\n\n\n\n\n\nname\nage\ncity\n\n\n\n\nb\nAnna\n36\nParis\n\n\nc\nPeter\n32\nBerlin\n\n\nd\nLinda\n45\nLondon\n\n\n\n\n\n\n\n\nSince we did not add inplace=True, the original DataFrame is not modified. We can confirm this by printing the original DataFrame:\n\ndf\n\n\n\n\n\n\n\n\n\nname\nage\ncity\n\n\n\n\na\nJohn\n23\nNew York\n\n\nb\nAnna\n36\nParis\n\n\nc\nPeter\n32\nBerlin\n\n\nd\nLinda\n45\nLondon\n\n\n\n\n\n\n\n\n\n\n5.2.3 Accessing Elements of a DataFrame\nWe are now familiar with some common ways of accessing specific rows and columns of a DataFrame. We are now ready to combine what we already know to access individual elements. We can use the loc attribute and pass the row and column index values:\n\n# access an element of the DataFrame\ndf.loc['a', 'name']\n\n'John'\n\n\nIf we know the numerical index of the row and column, we can use the iloc attribute:\n\n# get element from row 2 column 3\ndf.iloc[1, 2]\n\n'Paris'\n\n\nBy combining the techniques we learned, we can access multiple elements:\n\n# get multiple elements\ndf.loc[['a', 'c'], ['name', 'city']]\n\n\n\n\n\n\n\n\n\nname\ncity\n\n\n\n\na\nJohn\nNew York\n\n\nc\nPeter\nBerlin\n\n\n\n\n\n\n\n\n\n# first two rows\ndf[0:2][['name', 'age']]\n\n\n\n\n\n\n\n\n\nname\nage\n\n\n\n\na\nJohn\n23\n\n\nb\nAnna\n36",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas Basics</span>"
    ]
  },
  {
    "objectID": "pandas.html#conditional-selection",
    "href": "pandas.html#conditional-selection",
    "title": "5  Pandas Basics",
    "section": "5.3 Conditional selection",
    "text": "5.3 Conditional selection\nIt quite common in data science to filter data based on some condition. With Pandas, we can use the bracket notation to filter our data. Let’s first create a DataFrame with random numbers so that we can better illustrate this point:\n\n# creating a numeric only DataFrame\nfrom numpy.random import randn\nnp.random.seed(101)\n\ndf2 = pd.DataFrame(randn(3, 4), index = ['A', 'B', 'C'], columns = ['col1', 'col2', 'col3', 'col4'])\n\ndf2\n\n\n\n\n\n\n\n\n\ncol1\ncol2\ncol3\ncol4\n\n\n\n\nA\n2.706850\n0.628133\n0.907969\n0.503826\n\n\nB\n0.651118\n-0.319318\n-0.848077\n0.605965\n\n\nC\n-2.018168\n0.740122\n0.528813\n-0.589001\n\n\n\n\n\n\n\n\nNow, we can see that our DataFrame contains a bunch of numbers. Let’s say we want to find all the elements that are greater than 0. We can use the bracket notation to create a condition that returns a boolean DataFrame:\n\ndf2 &gt; 0\n\n\n\n\n\n\n\n\n\ncol1\ncol2\ncol3\ncol4\n\n\n\n\nA\nTrue\nTrue\nTrue\nTrue\n\n\nB\nTrue\nFalse\nFalse\nTrue\n\n\nC\nFalse\nTrue\nTrue\nFalse\n\n\n\n\n\n\n\n\nAs a result, we get a DataFrame with equal dimensions to the original DataFrame, but the numeric values have been replaced with True or False values based on the condition. We can use this boolean DataFrame to filter the original DataFrame:\n\ndf2[df2 &gt; 0]\n\n\n\n\n\n\n\n\n\ncol1\ncol2\ncol3\ncol4\n\n\n\n\nA\n2.706850\n0.628133\n0.907969\n0.503826\n\n\nB\n0.651118\nNaN\nNaN\n0.605965\n\n\nC\nNaN\n0.740122\n0.528813\nNaN\n\n\n\n\n\n\n\n\nNow we see that only the elements that satisfy the condition are displayed.\n\n5.3.1 Column based filtering\nIt is actually more common to select a subset of a DataFrame based on condition applied to a specific column. The idea is basically the same as we saw above. For example, let’s say we want to find all the elements in the col1 column that are greater than 0:\n\ndf2['col1'] &gt; 0\n\nA     True\nB     True\nC    False\nName: col1, dtype: bool\n\n\nThis returns a Pandas Series object with boolean values. We can use this Series object to filter the DataFrame:\n\ndf2[df2['col1'] &gt; 0]\n\n\n\n\n\n\n\n\n\ncol1\ncol2\ncol3\ncol4\n\n\n\n\nA\n2.706850\n0.628133\n0.907969\n0.503826\n\n\nB\n0.651118\n-0.319318\n-0.848077\n0.605965\n\n\n\n\n\n\n\n\nSimilarly, if we go back to our original DataFrame with the people data, we could filter the DataFrame based on the age column. Let’s say we want to find people over the age of 25:\n\ndf[df['age'] &gt; 25]\n\n\n\n\n\n\n\n\n\nname\nage\ncity\n\n\n\n\nb\nAnna\n36\nParis\n\n\nc\nPeter\n32\nBerlin\n\n\nd\nLinda\n45\nLondon\n\n\n\n\n\n\n\n\nVery convenient.\n\n\n5.3.2 Multiple conditions\nFiltering using multiple conditions is also possible. We can use the & (and) operator to combine the conditions. Let’s say we want to find people over the age of 25 who live in Paris:\n\ndf[(df['age'] &gt; 25) & (df['city'] == 'Paris')]\n\n\n\n\n\n\n\n\n\nname\nage\ncity\n\n\n\n\nb\nAnna\n36\nParis\n\n\n\n\n\n\n\n\nPlease note the syntax: we need to use parentheses around each condition. Also, we are not using the and keyword. We are using the & operator. This brings us to the next point: we can use the | (or) operator to combine conditions. Let’s say we want to find people younger than 25 or people who live in Paris:\n\ndf[(df['age'] &lt; 25) | (df['city'] == 'Paris')]\n\n\n\n\n\n\n\n\n\nname\nage\ncity\n\n\n\n\na\nJohn\n23\nNew York\n\n\nb\nAnna\n36\nParis\n\n\n\n\n\n\n\n\nPretty neat. We can also use the ~ (not) operator to negate a condition. Let’s say we want to find people who do not live in Paris:\n\ndf[~(df['city'] == 'Paris')]\n\n\n\n\n\n\n\n\n\nname\nage\ncity\n\n\n\n\na\nJohn\n23\nNew York\n\n\nc\nPeter\n32\nBerlin\n\n\nd\nLinda\n45\nLondon\n\n\n\n\n\n\n\n\nSince the result is also a DataFrame, we can interrogate the results as we would with any other DataFrame. For example, getting the names of people who do not live in Paris is easy:\n\ndf[~(df['city'] == 'Paris')]['name']\n\na     John\nc    Peter\nd    Linda\nName: name, dtype: object",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas Basics</span>"
    ]
  },
  {
    "objectID": "pandas.html#summary",
    "href": "pandas.html#summary",
    "title": "5  Pandas Basics",
    "section": "5.4 Summary",
    "text": "5.4 Summary\nIn this chapter, we learned about the basics of the Pandas library. In the next chapter, we will learn a little bit more about working with Pandas DataFrames, including how to handle missing data and how to group data.",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas Basics</span>"
    ]
  },
  {
    "objectID": "pandas_advanced.html",
    "href": "pandas_advanced.html",
    "title": "6  Working with DataFrames",
    "section": "",
    "text": "6.1 Common methods in Pandas\nWe already saw that the head() method displays the first five rows of the dataset. Five is the default value, but we can change in using the n parameter. Similarly, we can use the tail() method to display the last rows of the dataset.\n# Display the last nine rows\ndf.tail(9)\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n141\n6.9\n3.1\n5.1\n2.3\nvirginica\n\n\n142\n5.8\n2.7\n5.1\n1.9\nvirginica\n\n\n143\n6.8\n3.2\n5.9\n2.3\nvirginica\n\n\n144\n6.7\n3.3\n5.7\n2.5\nvirginica\n\n\n145\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n146\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n147\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n148\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n149\n5.9\n3.0\n5.1\n1.8\nvirginica\nThe info() method provides a concise summary of the dataset. It displays the number of non-null values in each column, the data type of each column, and the memory usage of the dataset.\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 150 entries, 0 to 149\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   sepal_length  150 non-null    float64\n 1   sepal_width   150 non-null    float64\n 2   petal_length  150 non-null    float64\n 3   petal_width   150 non-null    float64\n 4   species       150 non-null    object \ndtypes: float64(4), object(1)\nmemory usage: 6.0+ KB\nSummary statistics can be obtained using the describe() method. It provides the count, mean, standard deviation, minimum, maximum, and the quartiles of the dataset. This provides a handy way of getting an overall impression of the dataset.\ndf.describe()\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\n\n\ncount\n150.000000\n150.000000\n150.000000\n150.000000\n\n\nmean\n5.843333\n3.057333\n3.758000\n1.199333\n\n\nstd\n0.828066\n0.435866\n1.765298\n0.762238\n\n\nmin\n4.300000\n2.000000\n1.000000\n0.100000\n\n\n25%\n5.100000\n2.800000\n1.600000\n0.300000\n\n\n50%\n5.800000\n3.000000\n4.350000\n1.300000\n\n\n75%\n6.400000\n3.300000\n5.100000\n1.800000\n\n\nmax\n7.900000\n4.400000\n6.900000\n2.500000\nIf we just want to know the number of rows and columns in the dataset, we can use the shape attribute.\ndf.shape\n\n(150, 5)\nThe columns attribute provides the names of the columns in the dataset.\ndf.columns\n\nIndex(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n       'species'],\n      dtype='object')\nThe nunique() method provides the number of unique values in each column of the dataset.\ndf.nunique()\n\nsepal_length    35\nsepal_width     23\npetal_length    43\npetal_width     22\nspecies          3\ndtype: int64",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Working with DataFrames</span>"
    ]
  },
  {
    "objectID": "pandas_advanced.html#grouping-data",
    "href": "pandas_advanced.html#grouping-data",
    "title": "6  Working with DataFrames",
    "section": "6.2 Grouping data",
    "text": "6.2 Grouping data\nIf you are familiar with SQL queries, you might have used the GROUP BY clause to group data based on a particular column. Pandas provides a similar functionality using the groupby() method. Grouping data allows you to calculate for example statistics like the mean for distinct groups in the dataset. Let’s take a look at how this works by grouping the iris data based on the species column and calculating the mean of the other columns.\n\ndf.groupby('species').mean()\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\n\n\nspecies\n\n\n\n\n\n\n\n\nsetosa\n5.006\n3.428\n1.462\n0.246\n\n\nversicolor\n5.936\n2.770\n4.260\n1.326\n\n\nvirginica\n6.588\n2.974\n5.552\n2.026\n\n\n\n\n\n\n\n\nWe can also target specific columns. Let’s see how this works by taking the sum of the sepal_length for each species.\n\ndf.groupby('species')['sepal_length'].sum()\n\nspecies\nsetosa        250.3\nversicolor    296.8\nvirginica     329.4\nName: sepal_length, dtype: float64\n\n\nSome commonly used aggregation functions to chain after a groupby clause are:\n\nmean()\nsum()\ncount()\nmin()\nmax()\n\nWe can also use the agg() method to apply multiple aggregation functions at once. Let’s by taking the count, min, and max of the sepal_length and sepal_width columns for each species.\n\ndf.groupby('species')[['sepal_length', 'sepal_width']].agg(['count', 'min', 'max'])\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\n\n\n\ncount\nmin\nmax\ncount\nmin\nmax\n\n\nspecies\n\n\n\n\n\n\n\n\n\n\nsetosa\n50\n4.3\n5.8\n50\n2.3\n4.4\n\n\nversicolor\n50\n4.9\n7.0\n50\n2.0\n3.4\n\n\nvirginica\n50\n4.9\n7.9\n50\n2.2\n3.8\n\n\n\n\n\n\n\n\nIf you want to get summary statistics per group, you can also use the describe() method.\n\n# let's get the summary statistics for all columns\n# and show results for the petal_length column\ndf.groupby('species').describe()['petal_length']\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nspecies\n\n\n\n\n\n\n\n\n\n\n\n\nsetosa\n50.0\n1.462\n0.173664\n1.0\n1.4\n1.50\n1.575\n1.9\n\n\nversicolor\n50.0\n4.260\n0.469911\n3.0\n4.0\n4.35\n4.600\n5.1\n\n\nvirginica\n50.0\n5.552\n0.551895\n4.5\n5.1\n5.55\n5.875\n6.9",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Working with DataFrames</span>"
    ]
  },
  {
    "objectID": "pandas_advanced.html#handling-missing-values",
    "href": "pandas_advanced.html#handling-missing-values",
    "title": "6  Working with DataFrames",
    "section": "6.3 Handling missing values",
    "text": "6.3 Handling missing values\nIn a perfect world, we would always work with complete data tables without any missing values. However, out in the wild we are often confronted with incomplete data, which is why dealing with missing values is an important skill to have. Pandas provides a few methods to handle missing values.\nLet’s look at our iris dataset and introduce some missing values.\n\n# one missing value to the sepal_length column row 3\ndf.loc[2, 'sepal_length'] = np.nan\ndf.head()\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\nNaN\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n\n\n\n\n\n\nThere are a couple of methods which help us determine if missing values are present. The following methods are commonly used:\n\nisnull(): returns a DataFrame of the same shape as the original dataset, where each cell is either True or False depending on whether the value is missing or not.\nnotnull(): returns the opposite of isnull(). It returns True if the value is not missing, and False otherwise.\nisna(): an alias for isnull().\nnotna(): an alias for notnull().\n\nThe isnull() method returns a DataFrame of the same shape as the original dataset, where each cell is either True or False depending on whether the value is missing or not.\n\ndf.head().isnull()\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n1\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2\nTrue\nFalse\nFalse\nFalse\nFalse\n\n\n3\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n4\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n\n\n\n\nThe isna() method does exactly the same thing as isnull(), which we can see in the example below.\n\ndf.head().isna()\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n1\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n2\nTrue\nFalse\nFalse\nFalse\nFalse\n\n\n3\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n4\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n\n\n\n\n\n\nThe notnull() method returns the opposite of isnull(). It returns True if the value is not missing, and False otherwise.\n\ndf.head()['sepal_length'].notnull()\n\n0     True\n1     True\n2    False\n3     True\n4     True\nName: sepal_length, dtype: bool\n\n\nRelated to missing values we can easily drop rows with missing values using the dropna() method. By default, it drops rows where at least one element is missing.\n\ndf.dropna().head()\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n\n\n\n\n\n\nThe dropna() method also has a parameter how which can be set to all. This will only drop rows where all elements are missing. It is also possible to drop columns with missing values by setting the axis parameter to 1. Let’s see how this works.\n\n# drop columns with missing values\ndf.dropna(axis=1).head()\n\n\n\n\n\n\n\n\n\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n3.6\n1.4\n0.2\nsetosa\n\n\n\n\n\n\n\n\n\n6.3.1 Filling missing values\nInstead of dropping rows with missing values, we can also fill them with a specific value. This is ofter referred to as imputation. The fillna() method allows us to fill missing values with a specific value. Let’s fill the missing values in the sepal_length column with the mean of the column.\n\n# use the mean of sepal_length column to fill in for missing values\ndf['sepal_length'] = df['sepal_length'].fillna(df['sepal_length'].mean())\ndf.head()\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.100000\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.900000\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n5.851007\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.600000\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.000000\n3.6\n1.4\n0.2\nsetosa\n\n\n\n\n\n\n\n\n\n\n6.3.2 Missing values for other data types\nSo far, we have only looked at missing values in numerical columns. However, missing values can also occur in categorical columns. Let’s introduce a missing value in the species column.\n\n# introduce a missing value in the species column\ndf.loc[2, 'species'] = np.nan\ndf.head()\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.100000\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.900000\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n5.851007\n3.2\n1.3\n0.2\nNaN\n\n\n3\n4.600000\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.000000\n3.6\n1.4\n0.2\nsetosa\n\n\n\n\n\n\n\n\nLet’s inspect the datatypes of the columns in the dataset.\n\ndf.dtypes\n\nsepal_length    float64\nsepal_width     float64\npetal_length    float64\npetal_width     float64\nspecies          object\ndtype: object\n\n\nWe can now try to impute the most common value in the species column for the missing value. Before we do that let’s show to use the mode() method to get the most common value in a column.\n\ndf['species'].mode()\n\n0    versicolor\n1     virginica\nName: species, dtype: object\n\n\nWe can see that mode returns a Series object. To get the actual value we can use the iloc method, or just use the mode()[0] method. Let’s use this to fill the missing value in the species column.\n\n# fill missing values in the species column with the most common value\ndf['species'] = df['species'].fillna(df['species'].mode()[0])\ndf.head()\n\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.100000\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.900000\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n5.851007\n3.2\n1.3\n0.2\nversicolor\n\n\n3\n4.600000\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.000000\n3.6\n1.4\n0.2\nsetosa\n\n\n\n\n\n\n\n\nObviously, here we have imputed the incorrect species in place of the missing value. In practice, you would need to be more careful and consider the context of the data before imputing missing values. However, this example shows how you can impute missing values in categorical columns. There is more to learn about missing values, but for now, we will leave it at this.",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Working with DataFrames</span>"
    ]
  },
  {
    "objectID": "pandas_advanced.html#joining-dataframes",
    "href": "pandas_advanced.html#joining-dataframes",
    "title": "6  Working with DataFrames",
    "section": "6.4 Joining DataFrames",
    "text": "6.4 Joining DataFrames\nQuite often we find ourselves working with multiple datasets that we need to combine. Pandas provides a few methods to join DataFrames. Let’s start by creating two DataFrames to demonstrate how this works.\n\nsales_regions = pd.DataFrame({\n    'region': ['North', 'South', 'East', 'West'],\n    'manager': ['John', 'Sara', 'Tom', 'Alice']\n})\n\n# sales for three years by region\nsales_results = pd.DataFrame({\n    'year': [2019, 2020, 2021, 2019, 2020, 2021, \n    2019, 2020, 2021, 2019, 2020, 2021],\n    'region': ['North', 'North', 'North', 'South', 'South', 'South', \n    'East', 'East', 'East', 'West', 'West', 'West'],\n    'sales': [1000, 1200, 1500, 800, 900, 1000, \n    700, 800, 900, 600, 700, 800]\n})\n\nsales_regions\n\n\n\n\n\n\n\n\n\nregion\nmanager\n\n\n\n\n0\nNorth\nJohn\n\n\n1\nSouth\nSara\n\n\n2\nEast\nTom\n\n\n3\nWest\nAlice\n\n\n\n\n\n\n\n\n\nsales_results\n\n\n\n\n\n\n\n\n\nyear\nregion\nsales\n\n\n\n\n0\n2019\nNorth\n1000\n\n\n1\n2020\nNorth\n1200\n\n\n2\n2021\nNorth\n1500\n\n\n3\n2019\nSouth\n800\n\n\n4\n2020\nSouth\n900\n\n\n5\n2021\nSouth\n1000\n\n\n6\n2019\nEast\n700\n\n\n7\n2020\nEast\n800\n\n\n8\n2021\nEast\n900\n\n\n9\n2019\nWest\n600\n\n\n10\n2020\nWest\n700\n\n\n11\n2021\nWest\n800\n\n\n\n\n\n\n\n\nGiven these DataFrames, might want to join them based on the region column. We could for example calculate the total sales per region, and add the information to the sales_regions DataFrame. We can do this using the merge() method. Let’s see how this works.\n\n# let's first calculate the total sales per region\nsales_per_region = sales_results.groupby('region')['sales'].sum().reset_index()\nsales_per_region\n\n\n\n\n\n\n\n\n\nregion\nsales\n\n\n\n\n0\nEast\n2400\n\n\n1\nNorth\n3700\n\n\n2\nSouth\n2700\n\n\n3\nWest\n2100\n\n\n\n\n\n\n\n\nWe used the groupby() method we learned earlier to calculate the total sales per region. We then used the reset_index() method to convert the grouped data back to a DataFrame. Now we can merge the sales_regions DataFrame with the sales_per_region DataFrame.\n\n# merge the sales_regions DataFrame with the sales_per_region DataFrame\nsales_regions.merge(sales_per_region, on='region', how='left')\n\n\n\n\n\n\n\n\n\nregion\nmanager\nsales\n\n\n\n\n0\nNorth\nJohn\n3700\n\n\n1\nSouth\nSara\n2700\n\n\n2\nEast\nTom\n2400\n\n\n3\nWest\nAlice\n2100\n\n\n\n\n\n\n\n\nIf you have ever used SQL, you might have noticed that this looks very similar to a SQL join. The on parameter specifies the column to join on, and the how parameter specifies the type of join. Most common choices for the how parameter are probably left, right, inner, and outer. The default value is inner.\n\n6.4.1 Concatenating DataFrames\nNow sometimes we have DataFrames where the content is different but the columns are the same. In this case we might want to concatenate the DataFrames. Let’s assume we have sales data from previous years that we want to add to the sales_results DataFrame.\n\nsales_results_2018 = pd.DataFrame({\n    'year': [2018, 2018, 2018, 2018],\n    'region': ['North', 'South', 'East', 'West'],\n    'sales': [500, 400, 300, 200]\n})\n\nsales_results_2018\n\n\n\n\n\n\n\n\n\nyear\nregion\nsales\n\n\n\n\n0\n2018\nNorth\n500\n\n\n1\n2018\nSouth\n400\n\n\n2\n2018\nEast\n300\n\n\n3\n2018\nWest\n200\n\n\n\n\n\n\n\n\nWe can see that the format of this DataFrame is the same as the sales_results DataFrame. We can concatenate the two DataFrames using the concat() method, which takes a list of DataFrames as input.\n\n# concatenate the sales results from different years\nsales_all =pd.concat([sales_results_2018, sales_results])\nsales_all\n\n\n\n\n\n\n\n\n\nyear\nregion\nsales\n\n\n\n\n0\n2018\nNorth\n500\n\n\n1\n2018\nSouth\n400\n\n\n2\n2018\nEast\n300\n\n\n3\n2018\nWest\n200\n\n\n0\n2019\nNorth\n1000\n\n\n1\n2020\nNorth\n1200\n\n\n2\n2021\nNorth\n1500\n\n\n3\n2019\nSouth\n800\n\n\n4\n2020\nSouth\n900\n\n\n5\n2021\nSouth\n1000\n\n\n6\n2019\nEast\n700\n\n\n7\n2020\nEast\n800\n\n\n8\n2021\nEast\n900\n\n\n9\n2019\nWest\n600\n\n\n10\n2020\nWest\n700\n\n\n11\n2021\nWest\n800\n\n\n\n\n\n\n\n\nAll looks good, but we can see that the index is not in order. We can reset the index using the reset_index() method.\n\nsales_all.reset_index(drop=True, inplace=True)\nsales_all\n\n\n\n\n\n\n\n\n\nyear\nregion\nsales\n\n\n\n\n0\n2018\nNorth\n500\n\n\n1\n2018\nSouth\n400\n\n\n2\n2018\nEast\n300\n\n\n3\n2018\nWest\n200\n\n\n4\n2019\nNorth\n1000\n\n\n5\n2020\nNorth\n1200\n\n\n6\n2021\nNorth\n1500\n\n\n7\n2019\nSouth\n800\n\n\n8\n2020\nSouth\n900\n\n\n9\n2021\nSouth\n1000\n\n\n10\n2019\nEast\n700\n\n\n11\n2020\nEast\n800\n\n\n12\n2021\nEast\n900\n\n\n13\n2019\nWest\n600\n\n\n14\n2020\nWest\n700\n\n\n15\n2021\nWest\n800\n\n\n\n\n\n\n\n\nThe drop=True parameter means that we want to get rid of the old index. The inplace=True parameter means that we want to modify the DataFrame in place, instead of creating a new DataFrame. This will make the index start from 0, and the changes are applied to the DataFrame.",
    "crumbs": [
      "Basic Data Manipulation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Working with DataFrames</span>"
    ]
  }
]