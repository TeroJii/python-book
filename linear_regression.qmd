---
jupyter: python3
---

# Linear regression

Linear regression is fancy way of describing the act of fitting a line through your data. What makes it powerful is it's simplicity. When we are facing a regression problem this is usually the first thing we should try before moving on to more complex models. If you are looking for a detailed explanation on the intricacies of linear regression, I recommend taking a closer look at the wonderful book by James, Witten, Hastie and Tibshirani titled `An Introduction to Statistical Learning` (@ISLP).

::: {.callout-tip}
## Regression in a nutshell

In regression we are trying to predict a numerical (continuous) variable based on one or more other variables. The variable we are trying to predict is called the dependent variable, and the variables we are using to make the prediction are called the independent variables. In the field of Data Science, the dependent variable can sometimes be called the outcome, and the independent variables might be referred to as features.
:::

## Simple linear regression

Simple linear regression is the most basic form of regression. It is used when we want to use the values of a single independent variable to predict the values for the dependent variable. To put it simply, the goal is to find the best-fitting straight line through the data. The equation for a simple linear regression model is:

$$
y = \beta_0 + \beta_1x \text{,}
$$

where $y$ is the dependent variable, $x$ is the independent variable, $\beta_0$ is the intercept, $\beta_1$ is the slope.

Let's see how we can implement simple linear regression in Python using the `scikit-learn` library. Scikit-learn is one of the most fundamental machine learning libraries for Python. It provides a wide range of tools for building machine learning models, including regression models. Before we start, we need to install the library. You can do this by running the following command in your terminal:

```bash
pip install scikit-learn
```

After installation, we are ready to implement a simple linear regression model. 
We will use data from the World Happiness Report 2019, which is available through Kaggle (@HappinessData2019). 
The World Happiness Report is a survey of the state of global happiness that ranks 156 countries by how happy their citizens perceive themselves to be. 
The dataset contains information about various factors that contribute to happiness, such as GDP per capita, social support, healthy life expectancy, freedom to make life choices, generosity, and perceptions of corruption (@tbl-happiness).

```{python}
#| label: tbl-happiness
#| tbl-cap: The first rows of the World Happiness Report 2019 dataset.
#| code-fold: false

import pandas as pd
import seaborn as sns

# get the diamonds dataset
happiness = pd.read_csv('data/WorldHappinessReport2019.csv')
happiness.head()
```

@fig-lmdiamonds demonstrates the use of the `lmplot()` function from the `seaborn` library to visualize the relationship between the `carat` and `price` columns in the `diamonds` dataset.

```{python}
#| label: fig-lmdiamonds
#| code-fold: false
#| fig-cap: A scatter plot showing the relationship between the happiness score and the GDP per capita.

sns.lmplot(x='GDP per capita', y='Score', data=happiness)

```